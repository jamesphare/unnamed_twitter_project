---
title: "Unnamed Twitter Project"
author: "James Hare"
date: "7/11/2020"
output:
  github_document: default
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rtweet)
library(tidytext)
library(lubridate)
```

I wonder who my favorite tweeters are.

```{r favorites}
#This is the code to get favorites, but it shouldn't run automatically due to
#rate limits
#
#james <- get_favorites("ProsccoSocialst", n = 3000)
#write_as_csv(james, "data/james.csv")

james <- read_csv("data/james.csv")

my_fav_tweeters <- james %>%
  count(screen_name, sort = TRUE)

head(my_fav_tweeters, 10)
```

I wonder who their favorites are.

```{r favs_favorites}

#Code that shouldn't run automatically due to rate limits
#
#my_favs_favs <- get_favorites(my_fav_tweeters$screen_name, n = 300)
#write_as_csv(my_favs_favs, "data/my_favs_favs.csv")

my_favs_favs <- read_csv("data/my_favs_favs.csv")

my_favs_fav_tweeters <- my_favs_favs %>%
  count(screen_name, sort = TRUE)

head(my_favs_fav_tweeters, 10)
```

I'm going to go ahead and follow anyone on this list who I'm not already following.

Let's see which words show up most often in tweets that I have favorited.

```{r}

remove_reg <- "&amp;|&lt;|&gt;"
tidy_james_favs <- james %>%
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = str_remove_all(text, remove_reg)) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(
    !word %in% stop_words$word,
    !word %in% str_remove_all(stop_words$word, "'"),
    str_detect(word, "[a-z]")
  )

word_count <- tidy_james_favs %>%
  filter(!str_detect(word, "^@")) %>%
  count(word, sort = TRUE) %>%
  #"people" shoes up way to often and doesn't tell us much
  filter(word != "people")

head(word_count, 20)
```

I guess I'm interested in Left politics and the uprising against racist police violence.

Let's see what words my favorites are favoriting.

```{r}

tidy_favs_favs <- my_favs_favs %>%
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = str_remove_all(text, remove_reg)) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(
    !word %in% stop_words$word,
    !word %in% str_remove_all(stop_words$word, "'"),
    str_detect(word, "[a-z]")
  )

favs_word_count <- tidy_favs_favs %>%
  filter(!str_detect(word, "^@")) %>%
  count(word, sort = TRUE) %>%
  #"people" shoes up way to often and doesn't tell us much
  filter(word != "people")

head(favs_word_count, 20)
```

A lot of overalap, but they seem more interested in that whole cancel culture letter than I am.

Now let's take a look at the words that I use in my own tweets.

```{r}
#james_tweets <- get_timeline("ProsccoSocialst", n = 3000)
#write_as_csv(james_tweets, "data/james_tweets.csv")
james_tweets <- read_csv("data/james_tweets.csv")

tidy_james_tweets <- james_tweets %>%
  mutate(tweet = nrow(james_tweets):1,
         date = as_date(created_at)) %>%
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = str_remove_all(text, remove_reg)) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(
    !word %in% stop_words$word,!word %in% str_remove_all(stop_words$word, "'"),
    str_detect(word, "[a-z]")
  )

tweets_word_count <- tidy_james_tweets %>%
  filter(!str_detect(word, "^@")) %>%
  count(word, sort = TRUE) %>%
  #"people" shoes up way to often and doesn't tell us much
  filter(word != "people")

head(tweets_word_count, 20)

my_twitter_sentiment <- tidy_james_tweets %>%
  inner_join(get_sentiments("bing")) %>%
  count(date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

ggplot(my_twitter_sentiment, aes(date, sentiment)) +
  geom_col(show.legend = FALSE)
```

I was not happy on the days when Bernie dropped out or when Kemp announced that bowling alleys could re-open.